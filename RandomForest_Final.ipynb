{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1fff722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: ['Approved with condition', 'Approved', 'Rejected']\n",
      "Labels after fillna():\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0| 2455|\n",
      "|  1.0| 1295|\n",
      "|  2.0| 1250|\n",
      "+-----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampling label 0.0: ratio = 1.00\n",
      "Oversampling label 1.0: ratio = 1.90\n",
      "Oversampling label 2.0: ratio = 1.96\n",
      "Balanced class distribution:\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0| 2544|\n",
      "|  1.0| 2465|\n",
      "|  2.0| 2481|\n",
      "+-----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics:\n",
      "accuracy: 0.84\n",
      "f1: 0.83\n",
      "weightedPrecision: 0.89\n",
      "weightedRecall: 0.84\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 801:=========================================>           (155 + 4) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  0.0|       0.0|  437|\n",
      "|  0.0|       1.0|  362|\n",
      "|  1.0|       1.0|  726|\n",
      "|  2.0|       2.0|  737|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# STEP 1: Import Libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import rand, col\n",
    "\n",
    "# STEP 2: Start Spark Session\n",
    "spark = SparkSession.builder.appName(\"Loan_RF_3Class_BestFix\").getOrCreate()\n",
    "\n",
    "# STEP 3: Load Data\n",
    "df = spark.read.csv(\"MC_loan_data.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# STEP 4: Define Features and Target\n",
    "safe_features = [\n",
    "    \"salary\", \"loan_term\", \"occupation\", \"contract_amount\",\n",
    "    \"installment_amount\", \"interest_rate\", \"brand\", \"model_name\",\n",
    "    \"fraud_alert_pm1\", \"contract_id\"\n",
    "]\n",
    "target = \"application_status\"\n",
    "df = df.select(safe_features + [target])\n",
    "\n",
    "# STEP 5: Filter only rows with non-null target\n",
    "df_clean = df.filter(col(target).isNotNull())\n",
    "\n",
    "# STEP 6: Fit StringIndexer from full df to include all labels\n",
    "label_indexer = StringIndexer(inputCol=target, outputCol=\"label\")\n",
    "label_model = label_indexer.fit(df)\n",
    "print(\"Label mapping:\", label_model.labels)\n",
    "\n",
    "# STEP 7: Transform label column\n",
    "data = label_model.transform(df_clean)\n",
    "\n",
    "# STEP 8: Fill missing feature values to prevent label loss\n",
    "# Numerical fill = 0, Categorical fill = 'unknown'\n",
    "fill_dict = {\n",
    "    \"salary\": 0,\n",
    "    \"loan_term\": 0,\n",
    "    \"contract_amount\": 0,\n",
    "    \"installment_amount\": 0,\n",
    "    \"interest_rate\": 0,\n",
    "    \"occupation\": \"unknown\",\n",
    "    \"brand\": \"unknown\",\n",
    "    \"model_name\": \"unknown\",\n",
    "    \"fraud_alert_pm1\": \"unknown\",\n",
    "    \"contract_id\": \"unknown\"\n",
    "}\n",
    "data = data.fillna(fill_dict)\n",
    "\n",
    "# STEP 9: Confirm all 3 labels exist\n",
    "print(\"Labels after fillna():\")\n",
    "data.groupBy(\"label\").count().orderBy(\"label\").show()\n",
    "\n",
    "# STEP 10: Oversample to balance all classes\n",
    "labels = data.select(\"label\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "class_counts = data.groupBy(\"label\").count().collect()\n",
    "class_count_map = {row['label']: row['count'] for row in class_counts}\n",
    "max_size = max(class_count_map.values())\n",
    "\n",
    "samples = []\n",
    "for l in labels:\n",
    "    class_df = data.filter(col(\"label\") == l)\n",
    "    ratio = max_size / class_count_map[l]\n",
    "    print(f\"Oversampling label {l}: ratio = {ratio:.2f}\")\n",
    "    sampled_df = class_df.sample(withReplacement=True, fraction=ratio, seed=42)\n",
    "    samples.append(sampled_df)\n",
    "\n",
    "data_balanced = samples[0]\n",
    "for s in samples[1:]:\n",
    "    data_balanced = data_balanced.union(s)\n",
    "\n",
    "# STEP 11: Confirm balanced dataset\n",
    "print(\"Balanced class distribution:\")\n",
    "data_balanced.groupBy(\"label\").count().orderBy(\"label\").show()\n",
    "\n",
    "# STEP 12: Feature Engineering\n",
    "categorical_cols = [\"occupation\", \"brand\", \"model_name\", \"fraud_alert_pm1\", \"contract_id\"]\n",
    "numeric_cols = [\"salary\", \"loan_term\", \"contract_amount\", \"installment_amount\", \"interest_rate\"]\n",
    "\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=c + \"_idx\", handleInvalid=\"keep\") for c in categorical_cols]\n",
    "encoders = [OneHotEncoder(inputCol=c + \"_idx\", outputCol=c + \"_vec\") for c in categorical_cols]\n",
    "final_features = numeric_cols + [c + \"_vec\" for c in categorical_cols]\n",
    "assembler = VectorAssembler(inputCols=final_features, outputCol=\"features\")\n",
    "\n",
    "# STEP 13: Train-Test Split\n",
    "data_shuffled = data_balanced.orderBy(rand())\n",
    "train_data, test_data = data_shuffled.randomSplit([0.7, 0.3], seed=2025)\n",
    "\n",
    "# STEP 14: Train Random Forest\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=100, maxDepth=10)\n",
    "\n",
    "# STEP 15: Build and Train Pipeline\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler, rf])\n",
    "model = pipeline.fit(train_data)\n",
    "\n",
    "# STEP 16: Predict\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# STEP 17: Evaluation\n",
    "print(\"Evaluation metrics:\")\n",
    "metrics = [\"accuracy\", \"f1\", \"weightedPrecision\", \"weightedRecall\"]\n",
    "for metric in metrics:\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=metric)\n",
    "    print(f\"{metric}: {evaluator.evaluate(predictions):.2f}\")\n",
    "\n",
    "# STEP 18: Confusion Matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "predictions.groupBy(\"label\", \"prediction\").count().orderBy(\"label\", \"prediction\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81e99f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-----+\n",
      "|application_status     |count|\n",
      "+-----------------------+-----+\n",
      "|Approved               |1295 |\n",
      "|Rejected               |1250 |\n",
      "|Approved with condition|2455 |\n",
      "+-----------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"application_status\").count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4042437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddd7de0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
